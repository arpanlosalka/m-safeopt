{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd4b0805",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Objective-and-safety-functions\" data-toc-modified-id=\"Objective-and-safety-functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Objective and safety functions</a></span></li><li><span><a href=\"#Define-search-space\" data-toc-modified-id=\"Define-search-space-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Define search space</a></span></li><li><span><a href=\"#Plot-objective-and-safety-functions\" data-toc-modified-id=\"Plot-objective-and-safety-functions-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Plot objective and safety functions</a></span></li><li><span><a href=\"#Build-Gaussian-Process-models\" data-toc-modified-id=\"Build-Gaussian-Process-models-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Build Gaussian Process models</a></span></li><li><span><a href=\"#M-SafeOpt-(for-finding-global-safe-optimum)\" data-toc-modified-id=\"M-SafeOpt-(for-finding-global-safe-optimum)-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>M-SafeOpt (for finding global safe optimum)</a></span></li><li><span><a href=\"#M-SafeOpt-(for-finding-optimal-safe-action-for-every-x)\" data-toc-modified-id=\"M-SafeOpt-(for-finding-optimal-safe-action-for-every-x)-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>M-SafeOpt (for finding optimal safe action for every x)</a></span></li><li><span><a href=\"#SafeOpt-MC-Algorithm\" data-toc-modified-id=\"SafeOpt-MC-Algorithm-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>SafeOpt-MC Algorithm</a></span></li><li><span><a href=\"#PredVar-Algorithm\" data-toc-modified-id=\"PredVar-Algorithm-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>PredVar Algorithm</a></span></li><li><span><a href=\"#Set-Acquisition-Rule\" data-toc-modified-id=\"Set-Acquisition-Rule-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Set Acquisition Rule</a></span></li><li><span><a href=\"#Run-Safe-Bayesian-Optimization\" data-toc-modified-id=\"Run-Safe-Bayesian-Optimization-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Run Safe Bayesian Optimization</a></span></li><li><span><a href=\"#Plot-results\" data-toc-modified-id=\"Plot-results-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Plot results</a></span></li><li><span><a href=\"#Pre-compute-values-for-regret-plots\" data-toc-modified-id=\"Pre-compute-values-for-regret-plots-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Pre-compute values for regret plots</a></span></li><li><span><a href=\"#Cumulative-regret-plot-(finding-global-safe-optimum):-$R_t/t$\" data-toc-modified-id=\"Cumulative-regret-plot-(finding-global-safe-optimum):-$R_t/t$-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>Cumulative regret plot (finding global safe optimum): $R_t/t$</a></span></li><li><span><a href=\"#Cumulative-regret-plot-(finding-safe-optimum-for-every-$x$):-$R'_t/t$\" data-toc-modified-id=\"Cumulative-regret-plot-(finding-safe-optimum-for-every-$x$):-$R'_t/t$-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>Cumulative regret plot (finding safe optimum for every $x$): $R'_t/t$</a></span></li><li><span><a href=\"#Cumulative-regret-plot-(finding-safe-optimum-for-every-$x$):-$R^{\\mathcal{X}}_t/t$\" data-toc-modified-id=\"Cumulative-regret-plot-(finding-safe-optimum-for-every-$x$):-$R^{\\mathcal{X}}_t/t$-16\"><span class=\"toc-item-num\">16&nbsp;&nbsp;</span>Cumulative regret plot (finding safe optimum for every $x$): $R^{\\mathcal{X}}_t/t$</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d55c77-3ee8-4d99-b954-2c31b7691b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install trieste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0190c9-773e-4411-848f-2e6efe886edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa7d3ac-0636-408d-b703-f5f8efb958b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8992003b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T14:53:49.766714Z",
     "start_time": "2023-10-10T14:53:49.757171Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import gpflow\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from trieste.experimental.plotting import (\n",
    "    plot_bo_points,\n",
    "    plot_function_2d,\n",
    ")\n",
    "\n",
    "import trieste\n",
    "from trieste.acquisition.rule import EfficientGlobalOptimization\n",
    "from trieste.data import Dataset\n",
    "from trieste.models import TrainableModelStack\n",
    "from trieste.models.gpflow import build_gpr, GaussianProcessRegression\n",
    "from trieste.space import Box, SearchSpace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dc9a2c",
   "metadata": {},
   "source": [
    "### Objective and safety functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefbf216",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T15:19:02.335738Z",
     "start_time": "2023-10-10T15:19:02.305370Z"
    }
   },
   "outputs": [],
   "source": [
    "from trieste.objectives.utils import mk_observer\n",
    "from trieste.types import TensorType\n",
    "from trieste.space import DiscreteSearchSpace\n",
    "import random\n",
    "\n",
    "from trieste.objectives import ScaledBranin\n",
    "scaled_branin = ScaledBranin.objective\n",
    "\n",
    "def obj_scaled_branin(x: TensorType) -> TensorType:\n",
    "    obj_tensor = scaled_branin(x)\n",
    "    obj_tensor = tf.squeeze(obj_tensor, -1)\n",
    "    return obj_tensor\n",
    "\n",
    "def g_syn_1(x: TensorType) -> TensorType:\n",
    "    x0 = x[..., :1]\n",
    "    y = x[..., 1:] + 1/3.0\n",
    "    safety_tensor = -2*(x0)*( tf.exp(y)*tf.sin(10*y) + tf.sin(5*y) + 5)/3\n",
    "    return tf.squeeze(safety_tensor, -1)\n",
    "\n",
    "def dose_efficacy(x: TensorType) -> TensorType:\n",
    "    x0 = x[..., :1]\n",
    "    x1 = x[..., 1:]\n",
    "    obj_tensor_1 = -1/(1+tf.exp(1 - 2*x0 - x1 + 4*x0**2 + x1**2))\n",
    "    return tf.squeeze(obj_tensor_1, -1)\n",
    "\n",
    "def dose_toxicity(x: TensorType) -> TensorType:\n",
    "    x0 = x[..., :1]\n",
    "    x1 = x[..., 1:]\n",
    "    obj_tensor_1 = -1/(1+tf.exp(-2*x0-1*x1))\n",
    "    return tf.squeeze(obj_tensor_1, -1)\n",
    "\n",
    "# Change to set different functions as objective/safety functions\n",
    "obj = dose_efficacy\n",
    "safety = dose_toxicity\n",
    "\n",
    "# Safety threshold\n",
    "h = 0.9  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3110db82-47d2-409b-8ecc-866606e1d90f",
   "metadata": {},
   "source": [
    "### Define search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a249dd54-dcba-4a77-8d0a-722582908b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb_funcs(x: TensorType) -> TensorType:\n",
    "    return tf.stack([obj(x), safety(x)], axis = -1)\n",
    "\n",
    "def comb_funcs_plot(x:TensorType) -> TensorType:\n",
    "    return -comb_funcs(x)\n",
    "\n",
    "observer = mk_observer(\n",
    "    comb_funcs\n",
    ")\n",
    "\n",
    "mins = [0, 0]\n",
    "maxs = [2, 1]\n",
    "\n",
    "data_dim = 2\n",
    "data_num_per_dim = tf.constant(200)\n",
    "\n",
    "coords_per_axis = tf.linspace(tf.constant(mins, dtype=tf.float64), tf.constant(maxs, dtype=tf.float64), data_num_per_dim, axis=-1)\n",
    "idx = list(range(1,coords_per_axis.shape[0]+1))\n",
    "idx[-1] = 0\n",
    "coords = tf.meshgrid(*tf.unstack(tf.gather(coords_per_axis, idx)))\n",
    "coords = [tf.reshape(xv, [-1]) for xv in coords]\n",
    "coords = tf.stack(coords, axis=-1)\n",
    "\n",
    "search_space = DiscreteSearchSpace(coords)\n",
    "\n",
    "num_objective = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa34360d-ee9d-48c6-8a91-6b3a112924b1",
   "metadata": {},
   "source": [
    "### Plot objective and safety functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7871c5d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T14:52:14.031403Z",
     "start_time": "2023-10-10T14:52:13.159267Z"
    }
   },
   "outputs": [],
   "source": [
    "_, ax = plot_function_2d(\n",
    "    comb_funcs_plot,\n",
    "    search_space.lower,\n",
    "    search_space.upper,\n",
    "    contour=True,\n",
    "    title=[\"Objective function\", \"Safety function\"],\n",
    "    figsize=(12, 5),\n",
    "    colorbar=True,\n",
    "    xlabel=\"$s$\",\n",
    "    ylabel=\"$x$\",\n",
    ")\n",
    "\n",
    "safety_true = -1*safety(coords).numpy().reshape([data_num_per_dim**(data_dim-1), data_num_per_dim])\n",
    "safety_true[safety_true > h] = -np.inf\n",
    "safe_s_max_true = np.argmax(safety_true, axis = -1)\n",
    "\n",
    "safe_boundary_true = np.hstack( (np.arange(data_num_per_dim**(data_dim-1)).reshape([data_num_per_dim**(data_dim-1), 1]), \n",
    "                            safe_s_max_true.reshape([data_num_per_dim**(data_dim-1), 1])) )\n",
    "boundary_points_true = [coords[x[0] * data_num_per_dim + x[1] ] for x in safe_boundary_true]\n",
    "\n",
    "ax[0, 1].plot([a[0] for a in boundary_points_true], [a[1] for a in boundary_points_true], color = \"red\", marker = '+', markevery = 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff027b3",
   "metadata": {},
   "source": [
    "### Build Gaussian Process models\n",
    "\n",
    "[Change GP parameters here, if necessary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fb25d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T15:19:08.991820Z",
     "start_time": "2023-10-10T15:19:08.981720Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "\n",
    "def build_model(data, variance):\n",
    "    variance = tf.math.reduce_variance(data.observations)\n",
    "    kernel = gpflow.kernels.Matern52(variance=variance, lengthscales=[.2, .2])\n",
    "    prior_scale = tf.cast(1.0, dtype=tf.float64)\n",
    "    kernel.variance.prior = tfp.distributions.LogNormal(\n",
    "        tf.cast(variance, dtype=tf.float64), prior_scale\n",
    "    )\n",
    "    \n",
    "    kernel.lengthscales.prior = tfp.distributions.LogNormal(\n",
    "        tf.math.log(kernel.lengthscales), prior_scale\n",
    "    )\n",
    "    \n",
    "    gpr = gpflow.models.GPR(data.astuple(), kernel, noise_variance=1e-5)\n",
    "    gpflow.set_trainable(gpr.likelihood, False)\n",
    "    return GaussianProcessRegression(gpr, num_kernel_samples=10)\n",
    "\n",
    "def build_stacked_independent_objectives_model(\n",
    "    data: Dataset, num_output: int, search_space: SearchSpace, variances = [1,1]\n",
    ") -> TrainableModelStack:\n",
    "    gprs = []\n",
    "    for idx in range(num_output):\n",
    "        single_obj_data = Dataset(\n",
    "            data.query_points, tf.gather(data.observations, [idx], axis=1)\n",
    "        )\n",
    "        gprs.append((build_model(single_obj_data, variances[idx]), 1))\n",
    "\n",
    "    return TrainableModelStack(*gprs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f68522",
   "metadata": {},
   "source": [
    "### M-SafeOpt (for finding global safe optimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad186db0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T15:25:24.563890Z",
     "start_time": "2023-10-10T15:25:24.525066Z"
    }
   },
   "outputs": [],
   "source": [
    "h = tf.constant(0.9, tf.float64)   #safety threshold\n",
    "\n",
    "beta_f = tf.constant(3.0, tf.float64)   #scaling factor for confidence interval of GP_f\n",
    "beta_g = tf.constant(3.0, tf.float64)   #scaling factor for confidence interval of GP_g\n",
    "\n",
    "from trieste.acquisition import (\n",
    "    SingleModelAcquisitionBuilder,\n",
    "    ExpectedImprovement,\n",
    "    Product,\n",
    ")\n",
    "\n",
    "class MSafeOpt(SingleModelAcquisitionBuilder):\n",
    "    def prepare_acquisition_function(self, model, dataset=None):\n",
    "        def acquisition(x):\n",
    "            global L_f\n",
    "            global l_g\n",
    "            \n",
    "            print(\"|\",end=\" \")\n",
    "            mean, var = model.predict(tf.squeeze(x, -2))\n",
    "            stddev = tf.math.sqrt(var)\n",
    "                        \n",
    "            mean_f = tf.reshape(mean[:,0], [mean.shape[0], 1])\n",
    "            mean_g = tf.reshape(mean[:,1], [mean.shape[0], 1])\n",
    "                                \n",
    "            stddev_f = tf.reshape(stddev[:,0], [mean.shape[0], 1])\n",
    "            stddev_g = tf.reshape(stddev[:,1], [mean.shape[0], 1])\n",
    "                                  \n",
    "            dims = tf.constant(x.shape[-1], mean.dtype)\n",
    "            num_per_dim = tf.math.pow(tf.cast(x.shape[0], tf.float64), 1. / dims)  # number of discrete points per dimension\n",
    "            num_per_dim = tf.cast(tf.math.round(num_per_dim), tf.int64)\n",
    "            dims = tf.cast(dims, tf.int64)\n",
    "            \n",
    "            UCB_f = - tf.reshape(mean_f, [mean.shape[0], 1]) + beta_f * tf.reshape(stddev_f,\n",
    "                                                                         [stddev.shape[0], 1])  # upper confidence bound\n",
    "            UCB_g = - tf.reshape(mean_g, [mean.shape[0], 1]) + beta_g * tf.reshape(stddev_g,\n",
    "                                                                         [stddev.shape[0], 1])  # upper confidence bound\n",
    "            LCB_f = - tf.reshape(mean_f, [mean.shape[0], 1]) - beta_f * tf.reshape(stddev_f,\n",
    "                                                                         [stddev.shape[0], 1])  # lower confidence bound\n",
    "            LCB_g = - tf.reshape(mean_g, [mean.shape[0], 1]) - beta_g * tf.reshape(stddev_g,\n",
    "                                                                         [stddev.shape[0], 1])  # lower confidence bound\n",
    "            \n",
    "            mask_less_g = tf.reshape(tf.math.less_equal(UCB_g, h), [mean.shape[0]])  # mask for all points with UCB <= h\n",
    "            mask_more_g = tf.reshape(tf.math.greater(UCB_g, h), [mean.shape[0], 1])  # mask for all points with UCB > h\n",
    "                        \n",
    "            # if no points have UCB > h, set s^{(x)}_t=1 for all x\n",
    "            if tf.math.count_nonzero(mask_more_g) == 0: \n",
    "                a = tf.zeros([num_per_dim ** (dims - 1), num_per_dim - 1], mean.dtype)\n",
    "                b = tf.ones([num_per_dim ** (dims - 1), 1], mean.dtype)\n",
    "                mask_combined = tf.concat([a, b], axis=-1)\n",
    "                return tf.math.multiply(tf.reshape(stddev_f, [stddev.shape[0], 1]),\n",
    "                                        tf.reshape(mask_combined, [stddev.shape[0], 1]))\n",
    "            \n",
    "            # mask for all points with s = 0\n",
    "            mask_zero_g = tf.reshape(tf.math.equal(tf.reshape(tf.squeeze(x, -2)[:, 0], \n",
    "                                                            [mean.shape[0], 1]), tf.constant(0, mean.dtype)), [mean.shape[0], 1])  \n",
    "                                  \n",
    "            mask_zero_g = tf.reshape(tf.math.logical_and(mask_more_g, mask_zero_g),\n",
    "                               [mean.shape[0], 1])  # mask for all points with s=0 and UCB > h\n",
    "                                  \n",
    "            mask_safe_g = tf.reshape(mask_less_g,  [mean.shape[0], 1])\n",
    "            mask_safe_g = tf.math.logical_or(mask_safe_g, mask_zero_g)\n",
    "\n",
    "            mask_less_g = tf.reshape(mask_less_g, [mean.shape[0], 1])\n",
    "\n",
    "            mask_combined_g = tf.reshape(tf.math.logical_or(mask_less_g, mask_zero_g), [mean.shape[0], 1])\n",
    "            mask_combined_g = tf.reshape(mask_combined_g, [num_per_dim ** (dims - 1), num_per_dim])\n",
    "            true_indices_g = tf.math.argmax(tf.reverse(mask_combined_g, [-1]), axis=-1)\n",
    "            const_g = (num_per_dim - 1) * tf.ones(num_per_dim ** (dims - 1), tf.int64)\n",
    "            true_indices_g = const_g - true_indices_g\n",
    "            mask_final_g = tf.zeros([num_per_dim ** (dims - 1), num_per_dim])\n",
    "            mask_final_g = tf.tensor_scatter_nd_add(mask_final_g,\n",
    "                                                  tf.stack([tf.range(num_per_dim ** (dims - 1)), true_indices_g], axis=1),\n",
    "                                                  tf.ones(num_per_dim ** (dims - 1)))\n",
    "            \n",
    "            safe_UCB_f = tf.math.multiply(tf.cast(mask_safe_g, tf.float64), UCB_f + tf.constant(1000, mean.dtype))\n",
    "            safe_UCB_f = tf.reshape(safe_UCB_f, [num_per_dim ** (dims - 1), num_per_dim])\n",
    "            max_values = tf.reduce_max(safe_UCB_f, axis = -1, keepdims=True)\n",
    "            mask_max_f = tf.greater_equal(safe_UCB_f, max_values)\n",
    "            max_values = max_values - tf.constant(1000, mean.dtype)\n",
    "\n",
    "            mask_final_g = tf.reshape(mask_final_g, [mean.shape[0], 1])\n",
    "            \n",
    "            # Eliminate suboptimal x's, and Limit expansion if suboptimal\n",
    "            input_s = tf.reshape(tf.squeeze(x, -2)[:, 0], [mean.shape[0], 1])\n",
    "            input_s_boundary = tf.math.multiply(input_s, tf.cast(mask_final_g, mean.dtype))\n",
    "            input_s_boundary = tf.reshape(input_s_boundary, [num_per_dim ** (dims - 1), num_per_dim])\n",
    "            input_s_boundary = tf.reduce_max(input_s_boundary, axis = -1, keepdims=True)\n",
    "            \n",
    "            input_s_boundary_tiled = tf.tile(input_s_boundary,  [1 , num_per_dim])\n",
    "            input_s_diff = tf.reshape(input_s, [num_per_dim ** (dims - 1), num_per_dim]) - input_s_boundary_tiled\n",
    "            \n",
    "            LCB_g_boundary = tf.math.multiply(LCB_g + tf.constant(1000, mean.dtype), tf.cast(mask_final_g, mean.dtype))\n",
    "            LCB_g_boundary = tf.reshape(LCB_g_boundary, [num_per_dim ** (dims - 1), num_per_dim])\n",
    "            LCB_g_boundary = tf.reduce_max(LCB_g_boundary, axis = -1 , keepdims=True) - tf.constant(1000, mean.dtype)\n",
    "            LCB_g_boundary = tf.tile(LCB_g_boundary,  [1,num_per_dim])\n",
    "            pessimistic_LCB_g = LCB_g_boundary + l_g*input_s_diff\n",
    "            pessimistic_mask_g = tf.less_equal(pessimistic_LCB_g, h)\n",
    "            \n",
    "            UCB_f_boundary =  tf.math.multiply(UCB_f + tf.constant(1000, mean.dtype), tf.cast(mask_final_g, mean.dtype))\n",
    "            UCB_f_boundary = tf.reshape(UCB_f_boundary, [num_per_dim ** (dims - 1), num_per_dim])\n",
    "            UCB_f_boundary = tf.reduce_max(UCB_f_boundary, axis = -1, keepdims=True) - tf.constant(1000, mean.dtype)\n",
    "            UCB_f_boundary = tf.tile(UCB_f_boundary,  [1,num_per_dim])\n",
    "            optimistic_UCB_f = UCB_f_boundary + L_f*input_s_diff\n",
    "            optimistic_UCB_f_masked = tf.math.multiply(optimistic_UCB_f+ tf.constant(1000, mean.dtype), tf.cast(pessimistic_mask_g, mean.dtype))\n",
    "            optimistic_UCB_f_max = tf.reduce_max(optimistic_UCB_f_masked, axis = -1, keepdims=True)-tf.constant(1000, mean.dtype)\n",
    "            \n",
    "            LCB_f_safe =  tf.math.multiply(LCB_f+tf.constant(1000, mean.dtype), tf.cast(mask_safe_g, mean.dtype))\n",
    "            LCB_f_safe = tf.reshape(LCB_f_safe, [num_per_dim ** (dims - 1), num_per_dim])\n",
    "            LCB_f_safe_max = tf.reduce_max(LCB_f_safe) - tf.constant(1000, mean.dtype)\n",
    "            \n",
    "            expd_mask = tf.greater(optimistic_UCB_f_max, LCB_f_safe_max)\n",
    "            expd_mask = tf.tile(expd_mask,[1, num_per_dim])\n",
    "            expd_mask = tf.reshape(expd_mask, [mean.shape[0], 1])\n",
    "                        \n",
    "            elim_mask = tf.greater(max_values, LCB_f_safe_max)\n",
    "            elim_mask = tf.tile(elim_mask, [1, num_per_dim])\n",
    "            elim_mask = tf.reshape(elim_mask, [mean.shape[0], 1])\n",
    "\n",
    "            elim_mask = tf.math.logical_or(elim_mask, expd_mask)       \n",
    "            \n",
    "            mask_final_g = tf.math.logical_and(tf.cast(mask_final_g, tf.bool), elim_mask)\n",
    "            mask_final_g = tf.math.logical_and(tf.cast(mask_final_g, tf.bool), expd_mask)        \n",
    "\n",
    "            mask_max_f = tf.reshape(mask_max_f, [mean.shape[0], 1])\n",
    "            mask_max_f = tf.math.logical_and(mask_max_f, elim_mask)\n",
    "            mask_final_f = tf.math.logical_or(tf.cast(mask_max_f, tf.bool), tf.cast(mask_final_g, tf.bool))\n",
    "            \n",
    "            \n",
    "            max_interval_f = beta_f * tf.math.multiply(tf.reshape(stddev_f, [stddev.shape[0], 1]),\n",
    "                                    tf.cast(mask_final_f, mean.dtype))\n",
    "            \n",
    "            max_interval_g = beta_g * tf.math.multiply(tf.reshape(stddev_g, [stddev.shape[0], 1]),\n",
    "                                    tf.cast(tf.reshape(mask_final_g, [stddev.shape[0], 1]), mean.dtype))\n",
    "            \n",
    "            return tf.maximum(max_interval_f, max_interval_g)\n",
    "                                          \n",
    "        return acquisition\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670866d2",
   "metadata": {},
   "source": [
    "### M-SafeOpt (for finding optimal safe action for every x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd59ca2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T15:25:37.557945Z",
     "start_time": "2023-10-10T15:25:37.510286Z"
    }
   },
   "outputs": [],
   "source": [
    "class MSafeOptX(SingleModelAcquisitionBuilder):\n",
    "    def prepare_acquisition_function(self, model, dataset=None):\n",
    "        def acquisition(x):\n",
    "            print(\"|\",end=\" \")\n",
    "            global L_f\n",
    "            global l_g\n",
    "            \n",
    "            mean, var = model.predict(tf.squeeze(x, -2))\n",
    "            stddev = tf.math.sqrt(var)\n",
    "                        \n",
    "            mean_f = tf.reshape(mean[:,0], [mean.shape[0], 1])\n",
    "            mean_g = tf.reshape(mean[:,1], [mean.shape[0], 1])\n",
    "                                \n",
    "            stddev_f = tf.reshape(stddev[:,0], [mean.shape[0], 1])\n",
    "            stddev_g = tf.reshape(stddev[:,1], [mean.shape[0], 1])\n",
    "                                  \n",
    "            dims = tf.constant(x.shape[-1], mean.dtype)\n",
    "            num_per_dim = tf.math.pow(tf.cast(x.shape[0], tf.float64), 1. / dims)  # number of discrete points per dimension\n",
    "            num_per_dim = tf.cast(tf.math.round(num_per_dim), tf.int64)\n",
    "            dims = tf.cast(dims, tf.int64)\n",
    "            \n",
    "            UCB_f = - tf.reshape(mean_f, [mean.shape[0], 1]) + beta_f * tf.reshape(stddev_f,\n",
    "                                                                         [stddev.shape[0], 1])  # upper confidence bound\n",
    "            UCB_g = - tf.reshape(mean_g, [mean.shape[0], 1]) + beta_g * tf.reshape(stddev_g,\n",
    "                                                                         [stddev.shape[0], 1])  # upper confidence bound\n",
    "            LCB_f = - tf.reshape(mean_f, [mean.shape[0], 1]) - beta_f * tf.reshape(stddev_f,\n",
    "                                                                         [stddev.shape[0], 1])  # lower confidence bound\n",
    "            LCB_g = - tf.reshape(mean_g, [mean.shape[0], 1]) - beta_g * tf.reshape(stddev_g,\n",
    "                                                                         [stddev.shape[0], 1])  # lower confidence bound\n",
    "            \n",
    "            mask_less_g = tf.reshape(tf.math.less_equal(UCB_g, h), [mean.shape[0]])  # mask for all points with UCB <= h\n",
    "            mask_more_g = tf.reshape(tf.math.greater(UCB_g, h), [mean.shape[0], 1])  # mask for all points with UCB > h\n",
    "                        \n",
    "            # if no points have UCB > h, set s^{(x)}_t=1 for all x\n",
    "            if tf.math.count_nonzero(mask_more_g) == 0: \n",
    "                a = tf.zeros([num_per_dim ** (dims - 1), num_per_dim - 1], mean.dtype)\n",
    "                b = tf.ones([num_per_dim ** (dims - 1), 1], mean.dtype)\n",
    "                mask_combined = tf.concat([a, b], axis=-1)\n",
    "                return tf.math.multiply(tf.reshape(stddev_f, [stddev.shape[0], 1]),\n",
    "                                        tf.reshape(mask_combined, [stddev.shape[0], 1]))\n",
    "            \n",
    "            # mask for all points with s = 0\n",
    "            mask_zero_g = tf.reshape(tf.math.equal(tf.reshape(tf.squeeze(x, -2)[:, 0], \n",
    "                                                            [mean.shape[0], 1]), tf.constant(0, mean.dtype)), [mean.shape[0], 1])  \n",
    "                                  \n",
    "            mask_zero_g = tf.reshape(tf.math.logical_and(mask_more_g, mask_zero_g),\n",
    "                               [mean.shape[0], 1])  # mask for all points with s=0 and UCB > h\n",
    "                                  \n",
    "            mask_safe_g = tf.reshape(mask_less_g,  [mean.shape[0], 1])\n",
    "            mask_safe_g = tf.math.logical_or(mask_safe_g, mask_zero_g)\n",
    "            \n",
    "            mask_less_g = tf.reshape(mask_less_g, [mean.shape[0], 1])\n",
    "\n",
    "            mask_combined_g = tf.reshape(tf.math.logical_or(mask_less_g, mask_zero_g), [mean.shape[0], 1])\n",
    "            mask_combined_g = tf.reshape(mask_combined_g, [num_per_dim ** (dims - 1), num_per_dim])\n",
    "            true_indices_g = tf.math.argmax(tf.reverse(mask_combined_g, [-1]), axis=-1)\n",
    "            const_g = (num_per_dim - 1) * tf.ones(num_per_dim ** (dims - 1), tf.int64)\n",
    "            true_indices_g = const_g - true_indices_g\n",
    "            mask_final_g = tf.zeros([num_per_dim ** (dims - 1), num_per_dim])\n",
    "            mask_final_g = tf.tensor_scatter_nd_add(mask_final_g,\n",
    "                                                  tf.stack([tf.range(num_per_dim ** (dims - 1)), true_indices_g], axis=1),\n",
    "                                                  tf.ones(num_per_dim ** (dims - 1)))\n",
    "\n",
    "            safe_UCB_f = tf.math.multiply(tf.cast(mask_safe_g, tf.float64), UCB_f)\n",
    "            safe_UCB_f = tf.reshape(safe_UCB_f, [num_per_dim ** (dims - 1), num_per_dim])\n",
    "            max_values = tf.reduce_max(safe_UCB_f, axis = -1, keepdims=True)\n",
    "            mask_max_f = tf.greater_equal(safe_UCB_f, max_values)\n",
    "            \n",
    "            mask_final_g = tf.reshape(mask_final_g, [mean.shape[0], 1])\n",
    "            \n",
    "            # Limit expansion if suboptimal\n",
    "            input_s = tf.reshape(tf.squeeze(x, -2)[:, 0], [mean.shape[0], 1])\n",
    "            input_s_boundary = tf.math.multiply(input_s, tf.cast(mask_final_g, mean.dtype))\n",
    "            input_s_boundary = tf.reshape(input_s_boundary, [num_per_dim ** (dims - 1), num_per_dim])\n",
    "            input_s_boundary = tf.reduce_max(input_s_boundary, axis = -1, keepdims=True)\n",
    "            \n",
    "            input_s_boundary_tiled = tf.tile(input_s_boundary,  [1 , num_per_dim])\n",
    "            input_s_diff = tf.reshape(input_s, [num_per_dim ** (dims - 1), num_per_dim]) - input_s_boundary_tiled\n",
    "            \n",
    "            \n",
    "            LCB_g_boundary = tf.math.multiply(LCB_g+tf.constant(1000, mean.dtype), tf.cast(mask_final_g, mean.dtype))\n",
    "            LCB_g_boundary = tf.reshape(LCB_g_boundary, [num_per_dim ** (dims - 1), num_per_dim])\n",
    "            LCB_g_boundary = tf.reduce_max(LCB_g_boundary, axis = -1 , keepdims=True) - tf.constant(1000, mean.dtype)\n",
    "            LCB_g_boundary = tf.tile(LCB_g_boundary,  [1,num_per_dim])\n",
    "            pessimistic_LCB_g = LCB_g_boundary + l_g*input_s_diff\n",
    "            pessimistic_mask_g = tf.less_equal(pessimistic_LCB_g, h)\n",
    "            \n",
    "            UCB_f_boundary =  tf.math.multiply(UCB_f, tf.cast(mask_final_g, mean.dtype))\n",
    "            UCB_f_boundary = tf.reshape(UCB_f_boundary, [num_per_dim ** (dims - 1), num_per_dim])\n",
    "            UCB_f_boundary = tf.reduce_max(UCB_f_boundary, axis = -1, keepdims=True)\n",
    "            UCB_f_boundary = tf.tile(UCB_f_boundary,  [1,num_per_dim])\n",
    "            optimistic_UCB_f = UCB_f_boundary + L_f*input_s_diff\n",
    "            optimistic_UCB_f_masked = tf.math.multiply(optimistic_UCB_f, tf.cast(pessimistic_mask_g, mean.dtype))\n",
    "            optimistic_UCB_f_max = tf.reduce_max(optimistic_UCB_f_masked, axis = -1, keepdims=True)\n",
    "            \n",
    "            LCB_f_safe =  tf.math.multiply(LCB_f+tf.constant(1000, mean.dtype), tf.cast(mask_safe_g, mean.dtype))\n",
    "            LCB_f_safe = tf.reshape(LCB_f_safe, [num_per_dim ** (dims - 1), num_per_dim])\n",
    "            LCB_f_safe_max = tf.reduce_max(LCB_f_safe, axis = -1, keepdims=True)  - tf.constant(1000, mean.dtype)  \n",
    "            \n",
    "            expd_mask = tf.greater(optimistic_UCB_f_max, LCB_f_safe_max)\n",
    "            expd_mask = tf.tile(expd_mask, [1,num_per_dim])\n",
    "            expd_mask = tf.reshape(expd_mask, [mean.shape[0], 1])\n",
    "            \n",
    "            mask_final_g = tf.math.logical_and(expd_mask, tf.cast(mask_final_g, tf.bool))\n",
    "            \n",
    "            mask_max_f = tf.reshape(mask_max_f, [mean.shape[0], 1])\n",
    "            mask_final_f = tf.math.logical_or(tf.cast(mask_max_f, tf.bool), tf.cast(mask_final_g, tf.bool))\n",
    "            \n",
    "            max_interval_f = beta_f * tf.math.multiply(tf.reshape(stddev_f, [stddev.shape[0], 1]),\n",
    "                                    tf.cast(tf.reshape(mask_final_f, [stddev.shape[0], 1]), mean.dtype))\n",
    "            max_interval_g = beta_g * tf.math.multiply(tf.reshape(stddev_g, [stddev.shape[0], 1]),\n",
    "                                    tf.cast(tf.reshape(mask_final_g, [stddev.shape[0], 1]), mean.dtype))\n",
    "            \n",
    "            return tf.maximum(max_interval_f, max_interval_g)\n",
    "                                          \n",
    "        return acquisition\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d971b1-94db-4a98-ba84-4cbad06b5faf",
   "metadata": {},
   "source": [
    "### SafeOpt-MC Algorithm\n",
    "\n",
    "\n",
    "[Modified as per the description in our paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e38d4fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T15:26:01.551055Z",
     "start_time": "2023-10-10T15:26:01.523892Z"
    }
   },
   "outputs": [],
   "source": [
    "class SafeOpt(SingleModelAcquisitionBuilder):\n",
    "    def prepare_acquisition_function(self, model, dataset=None):\n",
    "        def acquisition(x):\n",
    "            print(\"|\",end=\" \")\n",
    "            mean, var = model.predict(tf.squeeze(x, -2))\n",
    "            stddev = tf.math.sqrt(var)\n",
    "                        \n",
    "            mean_f = tf.reshape(mean[:,0], [mean.shape[0], 1])\n",
    "            mean_g = tf.reshape(mean[:,1], [mean.shape[0], 1])\n",
    "                                \n",
    "            stddev_f = tf.reshape(stddev[:,0], [mean.shape[0], 1])\n",
    "            stddev_g = tf.reshape(stddev[:,1], [mean.shape[0], 1])\n",
    "                                  \n",
    "            dims = tf.constant(x.shape[-1], mean.dtype)\n",
    "            num_per_dim = tf.math.pow(tf.cast(x.shape[0], tf.float64), 1. / dims)  # number of discrete points per dimension\n",
    "            num_per_dim = tf.cast(tf.math.round(num_per_dim), tf.int64)\n",
    "            dims = tf.cast(dims, tf.int64)\n",
    "            \n",
    "            UCB_f = - tf.reshape(mean_f, [mean.shape[0], 1]) + beta_f * tf.reshape(stddev_f,\n",
    "                                                                         [stddev.shape[0], 1])  # upper confidence bound\n",
    "            UCB_g = - tf.reshape(mean_g, [mean.shape[0], 1]) + beta_g * tf.reshape(stddev_g,\n",
    "                                                                         [stddev.shape[0], 1])  # upper confidence bound\n",
    "            LCB_f = - tf.reshape(mean_f, [mean.shape[0], 1]) - beta_f * tf.reshape(stddev_f,\n",
    "                                                                         [stddev.shape[0], 1])  # lower confidence bound\n",
    "            LCB_g = - tf.reshape(mean_g, [mean.shape[0], 1]) - beta_g * tf.reshape(stddev_g,\n",
    "                                                                         [stddev.shape[0], 1])  # lower confidence bound\n",
    "            \n",
    "            mask_less_g = tf.reshape(tf.math.less_equal(UCB_g, h), [mean.shape[0]])  # mask for all points with UCB <= h\n",
    "            mask_more_g = tf.reshape(tf.math.greater(UCB_g, h), [mean.shape[0], 1])  # mask for all points with UCB > h\n",
    "                                    \n",
    "            # mask for all points with s = 0\n",
    "            mask_zero_g = tf.reshape(tf.math.equal(tf.reshape(tf.squeeze(x, -2)[:, 0], \n",
    "                                                            [mean.shape[0], 1]), tf.constant(0, mean.dtype)), [mean.shape[0], 1])  \n",
    "                                  \n",
    "            mask_zero_g = tf.reshape(tf.math.logical_and(mask_more_g, mask_zero_g),\n",
    "                               [mean.shape[0], 1])  # mask for all points with s=0 and UCB > h\n",
    "                                  \n",
    "            mask_safe_g = tf.reshape(mask_less_g,  [mean.shape[0], 1])\n",
    "            mask_safe_g = tf.math.logical_or(mask_safe_g, mask_zero_g)\n",
    "\n",
    "            mask_less_g = tf.reshape(mask_less_g, [mean.shape[0], 1])\n",
    "\n",
    "            mask_combined_g = tf.reshape(tf.math.logical_or(mask_less_g, mask_zero_g), [mean.shape[0], 1])\n",
    "            mask_combined_g = tf.reshape(mask_combined_g, [num_per_dim ** (dims - 1), num_per_dim])\n",
    "            true_indices_g = tf.math.argmax(tf.reverse(mask_combined_g, [-1]), axis=-1)\n",
    "            const_g = (num_per_dim - 1) * tf.ones(num_per_dim ** (dims - 1), tf.int64)\n",
    "            true_indices_g = const_g - true_indices_g\n",
    "            mask_final_g = tf.zeros([num_per_dim ** (dims - 1), num_per_dim])\n",
    "            mask_final_g = tf.tensor_scatter_nd_add(mask_final_g,\n",
    "                                                  tf.stack([tf.range(num_per_dim ** (dims - 1)), true_indices_g], axis=1),\n",
    "                                                  tf.ones(num_per_dim ** (dims - 1)))\n",
    "                                  \n",
    "            correction_for_more_g = tf.cast(tf.cast(tf.math.count_nonzero(tf.reshape(mask_more_g, \n",
    "                                                [num_per_dim ** (dims - 1), num_per_dim]), -1), tf.bool), tf.int64)\n",
    "            correction_for_more_g = tf.tile(tf.reshape(correction_for_more_g, [num_per_dim ** (dims - 1), 1]), \n",
    "                                            [1, num_per_dim])\n",
    "            mask_final_g = tf.math.multiply(tf.cast(mask_final_g, tf.float64), tf.cast(correction_for_more_g, tf.float64))\n",
    "            \n",
    "            safe_UCB_f = tf.math.multiply(tf.cast(mask_safe_g, tf.float64), UCB_f)\n",
    "            safe_UCB_f = tf.reshape(safe_UCB_f, [num_per_dim ** (dims - 1), num_per_dim])\n",
    "            \n",
    "            mask_final_g = tf.reshape(mask_final_g, [mean.shape[0], 1])\n",
    "                        \n",
    "            LCB_f_safe =  tf.math.multiply(LCB_f + tf.constant(1000, mean.dtype), tf.cast(mask_safe_g, mean.dtype))\n",
    "            LCB_f_safe_max = tf.reduce_max(LCB_f_safe) - tf.constant(1000, mean.dtype)\n",
    "            \n",
    "            mask_max_f = tf.greater(safe_UCB_f, LCB_f_safe_max)\n",
    "            mask_max_f = tf.reshape(mask_max_f, [mean.shape[0], 1])\n",
    "\n",
    "            mask_final = tf.math.logical_or(tf.cast(mask_max_f, tf.bool), tf.cast(mask_final_g, tf.bool))\n",
    "            \n",
    "            max_interval_f = beta_f * tf.math.multiply(tf.reshape(stddev_f, [stddev.shape[0], 1]),\n",
    "                                    tf.cast(mask_final, mean.dtype))\n",
    "            \n",
    "            max_interval_g = beta_g * tf.math.multiply(tf.reshape(stddev_g, [stddev.shape[0], 1]),\n",
    "                                    tf.cast(tf.reshape(mask_final, [stddev.shape[0], 1]), mean.dtype))\n",
    "            \n",
    "            return tf.maximum(max_interval_f, max_interval_g)\n",
    "                                          \n",
    "        return acquisition\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98feaebd-cc84-4344-baa8-58be6beb07fa",
   "metadata": {},
   "source": [
    "### PredVar Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659652ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T15:26:05.971839Z",
     "start_time": "2023-10-10T15:26:05.947401Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "class PredVar(SingleModelAcquisitionBuilder):\n",
    "    def prepare_acquisition_function(self, model, dataset=None):\n",
    "        def acquisition(x):\n",
    "            \n",
    "            print(\"|\",end=\" \")\n",
    "            mean, var = model.predict(tf.squeeze(x, -2))\n",
    "            stddev = tf.math.sqrt(var)\n",
    "            \n",
    "            mean_f = tf.reshape(mean[:,0], [mean.shape[0], 1])\n",
    "            mean_g = tf.reshape(mean[:,1], [mean.shape[0], 1])\n",
    "                                \n",
    "            stddev_f = tf.reshape(stddev[:,0], [mean.shape[0], 1])\n",
    "            stddev_g = tf.reshape(stddev[:,1], [mean.shape[0], 1])\n",
    "                                  \n",
    "            dims = tf.constant(x.shape[-1], mean.dtype)\n",
    "            num_per_dim = tf.math.pow(tf.cast(x.shape[0], tf.float64), 1. / dims)  # number of discrete points per dimension\n",
    "            num_per_dim = tf.cast(tf.math.round(num_per_dim), tf.int64)\n",
    "            dims = tf.cast(dims, tf.int64)\n",
    "\n",
    "            \n",
    "            UCB_f = - tf.reshape(mean_f, [mean.shape[0], 1]) + beta_f * tf.reshape(stddev_f,\n",
    "                                                                         [stddev.shape[0], 1])  # upper confidence bound\n",
    "            UCB_g = - tf.reshape(mean_g, [mean.shape[0], 1]) + beta_g * tf.reshape(stddev_g,\n",
    "                                                                         [stddev.shape[0], 1])  # upper confidence bound\n",
    "\n",
    "            mask_less_g = tf.reshape(tf.math.less_equal(UCB_g, h), [mean.shape[0], 1])  # mask for all points with UCB <= h\n",
    "            mask_more_g = tf.reshape(tf.math.greater(UCB_g, h), [mean.shape[0], 1])  # mask for all points with UCB > h\n",
    "            \n",
    "            # mask for all points with s = 0\n",
    "            mask_zero_g = tf.reshape(tf.math.equal(tf.reshape(tf.squeeze(x, -2)[:, 0], \n",
    "                                                            [mean.shape[0], 1]), tf.constant(0, mean.dtype)), [mean.shape[0], 1])  \n",
    "                                  \n",
    "            mask_zero_g = tf.reshape(tf.math.logical_and(mask_more_g, mask_zero_g),\n",
    "                               [mean.shape[0], 1])  # mask for all points with s=0 and UCB > h\n",
    "            \n",
    "            mask_combined = tf.reshape(tf.math.logical_or(mask_less_g, mask_zero_g), [mean.shape[0], 1])\n",
    "            \n",
    "            stddev_f = tf.math.multiply(tf.reshape(stddev_f, [stddev.shape[0], 1]),\n",
    "                                    tf.cast(tf.reshape(mask_combined, [stddev.shape[0], 1]), mean.dtype))\n",
    "            stddev_g = tf.math.multiply(tf.reshape(stddev_g, [stddev.shape[0], 1]),\n",
    "                                    tf.cast(tf.reshape(mask_combined, [stddev.shape[0], 1]), mean.dtype))\n",
    "            \n",
    "            return tf.maximum(stddev_f, stddev_g)\n",
    "\n",
    "        return acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219f0418-c696-43a5-8cca-176dffd77b9e",
   "metadata": {},
   "source": [
    "### Set Acquisition Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d26182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T15:26:27.001389Z",
     "start_time": "2023-10-10T15:26:26.994276Z"
    }
   },
   "outputs": [],
   "source": [
    "L_f = tf.constant(0.436, tf.float64)  # dose efficacy\n",
    "l_g = tf.constant(0.035, tf.float64)  # dose toxicity\n",
    "\n",
    "# L_f = tf.constant(10.166, tf.float64)  #scaled_branin\n",
    "# l_g = tf.constant(0.86, tf.float64)  #g_syn_1\n",
    "\n",
    "acq = MSafeOpt()\n",
    "# acq = MSafeOptX()\n",
    "# acq = SafeOpt()\n",
    "# acq = PredVar()\n",
    "\n",
    "rule: EfficientGlobalOptimization = EfficientGlobalOptimization(builder=acq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3752787-91c5-4410-9a71-e2a9571b85e4",
   "metadata": {},
   "source": [
    "### Run Safe Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcd6c10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T16:20:34.536280Z",
     "start_time": "2023-10-10T15:54:26.963922Z"
    }
   },
   "outputs": [],
   "source": [
    "from trieste.ask_tell_optimization import AskTellOptimizer\n",
    "\n",
    "num_runs = 1\n",
    "num_steps = 50\n",
    "\n",
    "for num_run in range(1, num_runs+1):\n",
    "\n",
    "    model = build_stacked_independent_objectives_model(\n",
    "        initial_data, num_objective, search_space\n",
    "    )\n",
    "\n",
    "    num_initial_points = 2\n",
    "    initial_query_points = tf.constant([[0.0, maxs[0]*random.random()], [0.0, maxs[0]*random.random()]], dtype=tf.float64)\n",
    "    initial_data = observer(initial_query_points)\n",
    "    \n",
    "    ask_tell = AskTellOptimizer(search_space, initial_data, model, acquisition_rule = rule)\n",
    "    pred_means = []\n",
    "    pred_vars = []    \n",
    "    dataset = initial_data\n",
    "\n",
    "    for step in range(1, num_steps + 1):\n",
    "        print(f\"Run #{num_run}: Step #{step}\")\n",
    "        new_point = ask_tell.ask()\n",
    "        new_data_point = observer(new_point)\n",
    "        dataset = dataset + new_data_point\n",
    "        ask_tell.tell(dataset)       \n",
    "        \n",
    "        curr_mean, curr_var = model.predict(coords)\n",
    "        pred_means.append(curr_mean.numpy())\n",
    "        pred_vars.append(curr_var.numpy())\n",
    "\n",
    "model_f = model._models[0].model\n",
    "model_g = model._models[1].model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080e248f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T12:34:59.622255Z",
     "start_time": "2023-10-09T12:34:59.612248Z"
    }
   },
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882e7aa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T17:20:43.033695Z",
     "start_time": "2023-10-10T17:20:42.765779Z"
    }
   },
   "outputs": [],
   "source": [
    "def UCB_func(x):\n",
    "    means, variances = model_f.predict_f(x)\n",
    "    means = means.numpy()\n",
    "    std_devs = np.sqrt(variances.numpy())  \n",
    "    UCB_f = - means + beta_f.numpy()*(std_devs)\n",
    "    \n",
    "    means, variances = model_g.predict_f(x)\n",
    "    means = means.numpy()\n",
    "    std_devs = np.sqrt(variances.numpy())  \n",
    "    UCB_g = - means + beta_g.numpy()*(std_devs)    \n",
    "\n",
    "    return (UCB_f, UCB_g)\n",
    "    \n",
    "data_num_per_dim_plot = tf.constant(300)\n",
    "coords_per_axis = tf.linspace(tf.constant(mins, dtype=tf.float64), tf.constant(maxs, dtype=tf.float64), data_num_per_dim, axis=-1)\n",
    "idx = list(range(1,coords_per_axis.shape[0]+1))\n",
    "idx[-1] = 0\n",
    "coords_plot = tf.meshgrid(*tf.unstack(tf.gather(coords_per_axis, idx)))\n",
    "coords_plot = [tf.reshape(xv, [-1]) for xv in coords_plot]\n",
    "coords_plot = tf.stack(coords_plot, axis=-1)\n",
    "\n",
    "UCB_f, UCB_g = UCB_func(coords_plot)\n",
    "UCB_g = np.reshape(UCB_g, [data_num_per_dim**(data_dim-1), data_num_per_dim])\n",
    "UCB_g[UCB_g > h] = -np.inf\n",
    "safe_s_max = np.argmax(UCB_g, axis = -1)\n",
    "safe_boundary = np.hstack( (np.arange(data_num_per_dim**(data_dim-1)).reshape([data_num_per_dim**(data_dim-1), 1]), \n",
    "                            safe_s_max.reshape([data_num_per_dim**(data_dim-1), 1])) )\n",
    "boundary_points = [coords_plot[x[0] * data_num_per_dim + x[1] ] for x in safe_boundary]\n",
    "\n",
    "safety_true = -1*safety(coords_plot).numpy().reshape([data_num_per_dim**(data_dim-1), data_num_per_dim])\n",
    "safety_true[safety_true > h] = -np.inf\n",
    "safe_s_max_true = np.argmax(safety_true, axis = -1)\n",
    "\n",
    "safe_boundary_true = np.hstack( (np.arange(data_num_per_dim**(data_dim-1)).reshape([data_num_per_dim**(data_dim-1), 1]), \n",
    "                            safe_s_max_true.reshape([data_num_per_dim**(data_dim-1), 1])) )\n",
    "boundary_points_true = [coords_plot[x[0] * data_num_per_dim + x[1] ] for x in safe_boundary_true]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d2956",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T17:20:53.540602Z",
     "start_time": "2023-10-10T17:20:51.637759Z"
    }
   },
   "outputs": [],
   "source": [
    "query_points = dataset.query_points.numpy()[2:]\n",
    "observations = dataset.observations.numpy()[2:]\n",
    "\n",
    "_, ax = plot_function_2d(\n",
    "    comb_funcs_plot,\n",
    "    search_space.lower,\n",
    "    search_space.upper,\n",
    "    contour=True,\n",
    "    figsize=(12, 5),\n",
    "    title=[\"Objective function\", \"Safety function\"],\n",
    "    xlabel=\"$s$\",\n",
    "    ylabel=\"$x$\",\n",
    "    colorbar=True,\n",
    ")\n",
    "\n",
    "plot_bo_points(data_query_points, ax=ax[0, 0], num_init=0)\n",
    "plot_bo_points(data_query_points, ax=ax[0, 1], num_init=0)\n",
    "\n",
    "ax[0, 1].plot([a[0] for a in boundary_points], [a[1] for a in boundary_points], color = \"blue\", marker = 'x', markevery = 9)\n",
    "ax[0, 1].plot([a[0] for a in boundary_points_true], [a[1] for a in boundary_points_true], color = \"red\", marker = '+', markevery = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a17b2e2",
   "metadata": {},
   "source": [
    "### Pre-compute values for regret plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9fc404",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T16:20:57.077686Z",
     "start_time": "2023-10-10T16:20:57.057113Z"
    }
   },
   "outputs": [],
   "source": [
    "h = 0.9   # safety threshold\n",
    "\n",
    "obj_values = -1*obj(coords).numpy()\n",
    "safety_values = -1*safety(coords).numpy()\n",
    "\n",
    "safe_obj_values = np.copy(obj_values)\n",
    "safe_obj_values[safety_values > h] = -np.inf\n",
    "\n",
    "max_obj_values = np.max(np.reshape(safe_obj_values, [data_num_per_dim**(data_dim-1), data_num_per_dim]), axis = -1)\n",
    "max_obj_value = np.max(max_obj_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f531f47",
   "metadata": {},
   "source": [
    "### Cumulative regret plot (finding global safe optimum): $R_t/t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ebc442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T16:21:07.533690Z",
     "start_time": "2023-10-10T16:21:07.360037Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_cumulative_regret(\n",
    "    obs_values,\n",
    "    ax,\n",
    "    label,\n",
    "    obs_every = 2,\n",
    "    show_obs=False,\n",
    "    c = \"blue\",\n",
    "):\n",
    "    cum_values = np.cumsum(obs_values)\n",
    "    cum_values_t = [cum_values[i]/(i+1) for i in range(len(obs_values))]\n",
    "    ax.plot(cum_values_t, color=c, label=label + \" (Avg. Cumulative)\")\n",
    "        \n",
    "    if show_obs:\n",
    "        obs_values = np.array(obs_values)\n",
    "        ax.scatter(range(0,obs_values.shape[0], obs_every), obs_values[0::obs_every], c=c, marker='x', label=label+\" (Instantaneous)\")\n",
    "\n",
    "suboptimality = []\n",
    "obs_obj_values = observations[:, 0]\n",
    "for i in range(obs_obj_values.shape[0]-1):\n",
    "    curr_suboptimality = max_obj_value + obs_obj_values[i]\n",
    "    suboptimality += [curr_suboptimality]\n",
    "    \n",
    "_, ax = plt.subplots(1, 1)\n",
    "\n",
    "plot_cumulative_regret(\n",
    "    suboptimality, ax, label = \"Regret\", show_obs = True\n",
    ")\n",
    "\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_xlabel(\"t\",fontsize = 13)\n",
    "ax.set_ylabel(r\"$R_t/t$\",fontsize = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21862607",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T07:16:10.453477Z",
     "start_time": "2023-10-09T07:16:10.438419Z"
    }
   },
   "source": [
    "### Cumulative regret plot (finding safe optimum for every $x$): $R'_t/t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc4cbb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T18:18:37.890937Z",
     "start_time": "2023-10-09T18:18:37.462251Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_x_index(query_point):\n",
    "    return np.where(coords_per_axis.numpy()[0] == query_point[1])\n",
    "    \n",
    "suboptimality = []\n",
    "obs_obj_values = observations[:, 0]\n",
    "\n",
    "for i in range(obs_obj_values.shape[0]-1):\n",
    "    x_index = get_x_index(query_points[i])\n",
    "    curr_suboptimality = max_obj_values[x_index] + obs_obj_values[i]\n",
    "    suboptimality += [curr_suboptimality]\n",
    "    \n",
    "_, ax = plt.subplots(1, 1)\n",
    "\n",
    "plot_cumulative_regret(\n",
    "    suboptimality, ax, label = \"Regret\", show_obs = True\n",
    ")\n",
    "\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_xlabel(\"t\",fontsize = 13)\n",
    "ax.set_ylabel(r\"$R'_t/t$\",fontsize = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef182db",
   "metadata": {},
   "source": [
    "### Cumulative regret plot (finding safe optimum for every $x$): $R^{\\mathcal{X}}_t/t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45e7fa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T18:04:39.855439Z",
     "start_time": "2023-10-09T18:04:39.533167Z"
    }
   },
   "outputs": [],
   "source": [
    "suboptimality_max = []\n",
    "obj_values_reshaped = np.reshape(obj_values, [data_num_per_dim**(data_dim-1), data_num_per_dim])\n",
    "\n",
    "for i in range(1, len(pred_means)):\n",
    "    UCB_f = -pred_means[i][:,0] + beta_f.numpy()*pred_vars[i][:,0]\n",
    "    UCB_g = -pred_means[i][:,1] + beta_g.numpy()*pred_vars[i][:,1]\n",
    "    safe_UCB_f = UCB_f\n",
    "    safe_UCB_f[UCB_g > h] = -np.inf\n",
    "\n",
    "    max_UCB_f_index = np.argmax(np.reshape(safe_UCB_f, [data_num_per_dim**(data_dim-1), data_num_per_dim]), axis = -1)\n",
    "    obj_values_best = []\n",
    "    \n",
    "    for j in range(data_num_per_dim**(data_dim-1)):\n",
    "        obj_values_best.append(obj_values_reshaped[j, max_UCB_f_index[j]])\n",
    "\n",
    "    max_UCB_regret = max_obj_values - np.array(obj_values_best)\n",
    "    suboptimality_max.append(np.max(max_UCB_regret))\n",
    "\n",
    "_, ax = plt.subplots(1, 1)\n",
    "\n",
    "plot_cumulative_regret_x(\n",
    "    suboptimality_max, ax, label = \"Regret\", show_obs = True\n",
    ")\n",
    "\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_xlabel(\"t\",fontsize = 13)\n",
    "ax.set_ylabel(r\"$R^{\\mathcal{X}}_t/t$\",fontsize = 13)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
